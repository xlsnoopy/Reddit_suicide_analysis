{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f8e628f",
   "metadata": {},
   "source": [
    "# Connect to PRAW API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"\",\n",
    "    client_secret=\"\",\n",
    "    user_agent=\"\",\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    ")\n",
    "print(reddit.read_only)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd8cbbb",
   "metadata": {},
   "source": [
    "# Use Pushshift API to pull the author list (can be skipped, since the list is saved and provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe4503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pushshift_py import PushshiftAPI\n",
    "import datetime as dt\n",
    "\n",
    "api = PushshiftAPI()\n",
    "start_time = int(dt.datetime(2019, 1, 1).timestamp())\n",
    "end_time = int(dt.datetime(2020, 12, 31).timestamp())\n",
    "\n",
    "results2 = list(api.search_submissions(after=start_time, before=end_time,\n",
    "                                  subreddit='suicidewatch', \n",
    "                                  sort = 'asc', sort_type = 'created_utc',\n",
    "                                  filter=['author', 'id','title','selftext','subreddit']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d2 = pd.DataFrame(results2)\n",
    "d2.dropna(inplace = True)\n",
    "df2 = pd.DataFrame(d2['d_'].to_list())\n",
    "\n",
    "df2.columns = [\"submission_name\", \"submission_time\", \"submission_id\", \"submission_body\", \"subreddit\", \"submission_title\"]\n",
    "Authors_unique = df2['submission_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557d7353",
   "metadata": {},
   "source": [
    "# Load author list, and 3 already sampled lists (to be excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6869b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "author = pd.read_csv(\"Datasets/Authors_unique.csv\")\n",
    "author_train1 = pd.read_csv(\"Datasets/Authors_0610_5000.csv\")\n",
    "author_train2 = pd.read_csv(\"Datasets/Authors_0619_5000.csv\")\n",
    "author_train3 = pd.read_csv(\"Datasets/Authors_0621_5000.csv\")\n",
    "author_train1.columns = author_train2.columns\n",
    "author_train = pd.concat([author_train1,author_train2,author_train3])\n",
    "author = author[~author[\"0\"].isin(author_train[\"Name\"])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685616af",
   "metadata": {},
   "source": [
    "# Define the pipeline of selecting posts and comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdec50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_post_and_comment(author):\n",
    "    comment_of_poster = []\n",
    "    post = []\n",
    "    print(\"In \" + author)\n",
    "    comment_to_post = []\n",
    "    if author is not None:\n",
    "        try:\n",
    "            cmt_ls = list(reddit.redditor(author).comments.new(limit = None))\n",
    "            for cmt in cmt_ls:\n",
    "                comment_of_poster.append([author, cmt.subreddit, cmt.body, cmt.subreddit_id, cmt.link_title, cmt.created_utc])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            ls = []\n",
    "            sub_ls = list(reddit.redditor(author).submissions.new(limit = None))\n",
    "            \n",
    "            for submission in sub_ls:\n",
    "                if submission.created_utc >= int(dt.datetime(2019, 1, 1).timestamp()): \n",
    "                    ls.append([submission.subreddit])\n",
    "            if (pd.DataFrame(ls) == 'SuicideWatch').any().bool():\n",
    "                for submission in sub_ls:\n",
    "                    if submission.created_utc >= int(dt.datetime(2019, 1, 1).timestamp()): \n",
    "                        post.append([submission.author,submission.subreddit,  submission.selftext, submission.id,\n",
    "                            submission.title,submission.created_utc])\n",
    "                        submission.comments.replace_more(limit=None)\n",
    "                        for com in submission.comments.list():\n",
    "                            try:\n",
    "                                list(com.author.submissions.new(limit = None))\n",
    "                                comment_to_post.append([submission.id, com.author, com.body, com.created_utc])\n",
    "                            except Exception as e:\n",
    "                                pass\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    print(\"Out \" + author)\n",
    "    return post, comment_of_poster, comment_to_post\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0384f74a",
   "metadata": {},
   "source": [
    "# Create a multiprocessing executor and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf679631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "import timeit\n",
    "import datetime as dt \n",
    "import numpy as np\n",
    "\n",
    "start_time = timeit.default_timer() \n",
    "posts = pd.DataFrame({})\n",
    "comments_poster = pd.DataFrame({})\n",
    "comments_post = pd.DataFrame({})\n",
    "\n",
    "\n",
    "with futures.ProcessPoolExecutor(1000) as pool:\n",
    "    for post, comment_poster, comment_post in pool.map(extract_post_and_comment, author['0']):\n",
    "        if post:\n",
    "            posts = posts.append(pd.DataFrame(np.array(post)))\n",
    "        if comment_poster:\n",
    "            comments_poster = comments_poster.append(pd.DataFrame(np.array(comment_poster)))\n",
    "        if comment_post:\n",
    "            comments_post = comments_post.append(pd.DataFrame(np.array(comment_post)))\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0330af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.to_csv(\"post_rest.csv\")\n",
    "comments_poster.to_csv(\"comment_of_poster_rest.csv\")\n",
    "comments_post.to_csv(\"comment_to_post_rest.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
